# Java

### JDK 和 JRE 的区别：

**JRE (Java Runtime Enviroment)** ：Java 的运行时环境。面向的是 Java 程序的使用者，而不是开发者。JRE 中包含了 JVM 的标准实现及 Java 核心类库。

**JDK (Java Development Kit) **：Java 的开发工具包，提供了 Java 的开发环境（提供了 javac 等工具）和运行环境（提供了 JVM 和 Runtime 辅助包）。在完整安装 JDK 后，不仅可以开发 Java 程序，也同时拥有了运行 Java 程序的平台。



### StackOverFlow 和 OutOfMemory 出现的原因：

**栈溢出**：每一个 JVM 线程都拥有一个私有的 JVM 线程栈，用于存放当前线程的 JVM 栈帧。**如果某个线程的线程栈空间被耗尽，没有足够资源分配给新创建的栈帧，就会抛出java.lang.StackOverflowError 错误。**

**可能产生的原因**：

1. 递归调用过深，没有跳出递归的条件。
2. 执行了大量的方法，导致线程栈空间耗尽。
3. 不断的创建线程。

**内存溢出**：创建对象的速度高于 GC 回收速度，或者内存泄露等都会导致内存溢出。简单地说内存溢出就是，程序运行过程中申请的内存大于系统能够提供的内存，导致无法申请到足够的内存。



### 抽象类和抽象方法的区别：

抽象类不可以被实例化，抽象方法所在的类一定是抽象类，抽象类可以没有抽象方法。

抽象方法：abstract 修饰的方法是抽象方法。抽象方法没有方法体，只保留方法的功能，具体的执行，交给继承抽象类的子类，由子类重写抽象方法。

**Notice**：如果子类继承抽象类，并重写了父类的所有抽象方法，则此子类不是抽象类，可以实例化。如果子类继承抽象类，但是没有重写父类所有的抽象方法，那么这个子类就必须申明为抽象的。



### 接口和抽象类的区别：

1. 接口的方法默认是 public，所有方法在接口中不能有实现，而抽象类可以有非抽象方法。抽象方法可以有 public、protected 和 default 这些修饰符。（抽象方法就是为了被重写，所以不能使用 private 关键字修饰）

2. 接口中除了 static、final 变量，不能有其他变量，而抽象类中则不一定。

3. 一个类可以实现多个接口，但只能继承一个抽象类。接口自己本身可以通过 extends 关键字扩展多个接口。

4. 从设计层面来讲，抽象是对类对抽象，是一种模版设计，而接口是对行为的抽象，是对行为的规范。

   

### sleep() 和 wait() 方法的区别：

两者都能暂停线程。但是 sleep 没有释放锁，而 wait 释放锁。 wait 常被用于线程间通信，sleep 则用来暂停执行。 wait 方法调用后，线程不会自动苏醒，需要别的线程调用同一对象的 notify 或 notifyAll 方法。sleep 方法执行完成后，线程会自动苏醒。



### 为什么不调用 run() ？ 而需要调用 start() ?

New Thread() 线程会进入新建状态，调用 start 方法会启动一个线程并使其进入就入就绪状态，等待分配 CPU 时间片就可以运行了。 start 会执行线程相应的准备工作，然后自动执行 run 方法的内容（真的多线程）。直接调用 run 方法相当于在主线程执行普通方法。



### JVM 运行时数据区域

**程序计数器**：字节码解释器通过改变程序计数器的值来选取下一条需要执行的命令。分支、循环、跳转、异常处理、线程恢复都依赖这个计数器完成。

**虚拟机栈**：线程私有，生命周期同线程相同，描述的是 Java 方法执行的内存模型。每次方法调用的数据都是通过栈传递的。**由栈帧组成， 栈帧中有局部变量表，操作数栈，动态链接和方法出口信息。**

**本地方法栈**：与虚拟机栈相似，虚拟机栈为虚拟机执行 Java 方法服务。本地方法栈则为虚拟机使用到的 Native 方法服务。

**堆**：Java虚拟机中管理内存最大的一块，唯一的目的就是存放对象实例，几乎所有对象以及数组都在这里分配内存。

**方法区**：各线程共享的内存区域。用于存储已被虚拟机加载的类信息、常量、静态变量，即时编译器编译后的代码等数据。



### Java 对象创建过程

1. 类加载检查：虚拟机遇到 new 关键字，就检查指令参数在常量池中是否存在符号引用，并且检查这个符号引用的类是否已被加载、解析、初始化过。如果没有，需要首先执行相应的类加载过程。
2. 分配内存：对象所需要的内存大小在类加载完成之后便可以确定，这一步就是在 Java 堆中划分出一块确定大小的内存。内存的分配方式有“指针碰撞”和“空闲列表”两种，选取哪种方式取决于 Java 堆是否规整。
3. 初始化零值：将分配到的内存空间（除对象头外）初始化零值。这一步操作保证了对象的实例字段在 Java 代码中可以不赋初始值就能使用（访问到的是数据类型对应的零值）。
4. 设置对象头：虚拟机对对象进行必要的设置，如这个对象是哪个类的实例，如何才能找到类的元数据信息，对象的哈希码，对象的 GC 分代年龄信息，这些信息都保存在对象头中。
5. 执行 init() 方法：按照程序猿的意愿进行初始化。



### 对象访问定位的两种方式？

Java 程序通过栈上的 Reference 数据来操作堆上的具体数据。目前主流的访问方式有两种：1.句柄 2.直接指针

1. 句柄：Java 堆会划分出一块内存作为句柄池，Reference 中存储的是对象的句柄地址，而句柄中包含了对象实例数据与类型数据各自的具体地址信息。
2. 直接指针：Reference 存储的是对象实例数据的地址，对象实例数据中存储对象类型数据地址。

优势：句柄：Reference 存储的是稳定的句柄地址，对象移动时只需要改变句柄中的数据指针。

直接指针：速度快，节省一次指针定位的时间开销。



### Java 的四种引用类型：

1. 强引用：Object o = new Object() 这种对象永远不会被回收，即时内存不足，JVM 抛出 OOM，也不会回收。

2. 软引用：SoftReference<Object> o = new SoftReference<Object(new Object)>

   ​               Object temp = o.get()	

   需要用 SoftReference 包裹对象，使用 get 获取这个对象。特点是当内存不足，不会第一时间收集。当GC后，内存仍不足，就会把软引用包裹的对象回收。（可以用来做网页图片缓存）

3. 弱引用：WeakReference<Object> o = new WeakReference<Object(new Object)>

   ​               Object temp = o.get()	

   特点：只要触发 GC，就会把弱引用包裹的对象回收。

4. 虚引用：特点：只要触发 GC ，就会把虚引用包裹的对象回收，并把回收的通知放到 ReferenceQueue 中（必须配合使用）



### 堆内存中对象的分配策略：

1. 对象优先在 eden 区分配 
2. 大对象直接进入老年代
3. 长期存活的对象将进入老年代



### 判断对象死亡的 2 种方法？

1. 引用计数法
2. 可达性分析法



### 垃圾回收算法

1. **标记 - 清除算法**：两轮遍历，第一轮标记存活对象，第二轮清除需要回收的对象。

   问题：效率低，空间问题（会产生大量不连续的碎片）

2. **标记 - 整理算法**：第一轮标记存活对象，后续不直接对可回收对象回收，而是让所有存活对象向一端移动，直接清理掉端边界以外垃圾对象。

3. **复制算法**：解决了效率问题。将内存分为两个大小相同的块，每次使用一块，当一块内存使用完后，就将还存活的对象复制到另一块去，然后再把使用的空间一次性处理掉。

4. **分代收集**：根据对象存活周期不同，将内存分为几块（新生代，老年代），各代根据特点选择合适的垃圾收集算法。

   新生代：大量对象死亡，有辅助空间，需要高效回收，使用复制算法。

   老年代：存活率高，没有额外的辅助空间，使用标记 - 清除， 标记 - 整理算法。



### 常见的垃圾收集器

...

Serial 收集器：只使用一条垃圾收集线程去完成垃圾收集工作，并且在进行垃圾收集工作的时候，必须暂停其他的工作线程（stop-the-world），直到它结束。

Par New 收集器：Serial 收集器的多线程版本。

Parallel Scavenge 收集器：关注吞吐量，高效率运用 CPU

Serial Old 收集器：Serial 收集器的老年代版本。

Parallel Old 收集器：Parallel Scavenge 收集器的老年代版本，使用多线程的标记 - 整理算法。

CMS 收集器：更多关注用户线程的停顿时间，提高用户体验，第一次实现了让垃圾收集线程与用户线程（基本上）同时工作。整体过程分为 4 步：

第一步：初始标记：暂停所有其他线程，并记录下直接与 root 相连的对象。

第二步：并发标记：同时开启 GC 和用户线程，用一个闭包结构去记录可达对象。但是在这个阶段结束后，闭包结构不能保证包含当前所有可达对象（因为用户线程可能会不断的更新引用域，所以 GC 线程无法保证可达性分析的实时性）。

第三步：重新标记：修正并发标记期间因用户程序继续运行而导致标记产生的变动。

第四步：并发清除：开启用户线程，同时 GC 线程开始对未标记区域进行清除。

优点：实现了并发收集和低停顿。

缺点：1.对 CPU 敏感。 2.无法处理**浮动垃圾** 3.采用 “标记 - 清除” 算法产生空间碎片。



#### 创建线程的几种方式：

1. 继承 Thread 类，并重写 run() 方法
2. 实现 Runnable 接口，并实现 run() 方法
3. 实现 Callable 接口，实现 call() 方法，并结合 FutureTask 实现。 call() 方法是带有返回值的。
4. 通过线程池创建线程。



### ThreadPoolExecutor 参数：

1. corePoolSize ： 核心线程数量，它的数量决定了添加的任务是开辟新线程执行还是放到 workQueue 队列中。

2. maximunPoolSize ：线程池中的最大线程数量。

3. KeepAliveTime ：超出 corePoolSize 的线程能够存活的时间。

4. Unit ：KeepAliveTime 参数的单位。

5. workQueue ：任务队列，有四种取值。

   ArrayBlockingQueue ： 有界数组队列，先进先出，创建时必须指定大小。

   SynchronousQueue ：同步阻塞队列，不保存提交的任务，直接新建线程执行新来的任务。

   LinkedBlockingQueue ：基于链表的先进先出序列，支持有界 / 无界队列。

   PriorityBlockingQueue ：优先队列，可针对任务进行排序。

6. ThreadFactory ：线程创建的工厂。

7. Handler ：拒绝策略，当达到最大线程量，并且队列已满时触发。

   AbortPolicy ：抛出 RejectedExecutionException，拒绝新任务处理。

   CallerRunsPolicy ：调用执行自己的线程运行任务。

   DiscardPolicy ：不处理新任务，直接丢弃掉。

   DiscardOldestPolicy ：丢弃最早的未处理的任务请求。



### 并发编程中的三个概念：

1. 原子性：一个或多个操作，要么都执行，要么都不执行。

2. 可见性：当多线程访问一个变量时，一个线程修改了变量值，其他线程应当能立即看到修改后的值。

3. 有序性：程序执行的顺序按照代码顺序执行。

   可能发生指令重排，（处理器为提效，可能对输入代码做优化，不保证程序中各语句的执行先后顺序同代码相同，但是保证最后结果同顺序执行结果一致），指令重排在单线程的情况下没有问题，多线程并发则会出现问题。

   一线程：

   ```
   context = loadContext();
   
   inited = true; (指令重排，先执行这句话)
   ```

   二线程：

   ```
   while(inited){
   	sleep();
   }
   doSomething();
   ```

   上例会导致一线程还未初始化，二线程便 doSomething()，这是不应该的。



### volatile 关键字

volatile ：一个变量被 volatile 修饰后，便具备两层语义：

一、保证不同线程对这个变量操作的可见性。

        1. 使用 volatile 关键字会强制将修改的值写入内存。
        2. 线程二修改变量值，会使线程一缓存的变量值无效。
        3. 由于线程一缓存变量无效，而重新从内存中读取。

二、禁止指令重排

​	保证在指令优化时，volatile 前的语句不会在 volatile 后执行。volatile 后的语句也不会在 volatile 前执行。



volatile ---> 汇编代码出现 lock 指令 ---> 施加内存屏障

1. 执行到内存屏障时，保证之前的语句都完成。
2. 对缓存修改立即写入内存。
3. 写操作导致缓存无效。



### synchronized 关键字

synchronized 的三种使用形式：

1. 修饰普通的方法：锁当前实例对象
2. 修饰静态方法：锁当前类 class 对象  （两个不同的锁，可同时获取）
3. 修饰代码块：锁括号里配置的对象

Notice ：

1. synchronized 修饰非静态方法和代码块，同一类不同对象有自己的锁，所以不阻塞。
2. synchronized 修饰实例对象，若正在访问实例对象的同步方法，则不能访问该实例的其他同步方法。
3. 线程 A 访问非静态 synchronized 方法， 线程 B 访问静态 synchronized 方法时并不互斥，获取的是两个不同的锁。

synchronized 锁的四种状态：无锁，偏向锁，轻量级锁，重量级锁

初次执行到 synchronized 代码块时，锁对象变成偏向锁（通过 CAS 修改对象头的锁标志位）。执行完代码不会主动释放锁，当第二次到达同步代码块时，判断此时持有锁的对象是否是自己？是的话就正常执行（没有锁释放和加锁操作，如果自始至终只有一个使用锁的线程，那么几乎没有额外开销，性能很高）。

Notice ： 偏向锁撤锁或升级锁的过程 ： 1.等待全局安全点  ---> 暂停偏向锁线程 ---> 检查锁对象锁定状态 ---> 线程不活动 ---> 设置对象头（无锁或轻量锁）

当锁是偏向锁，却被其他线程访问，偏向锁会升级为轻量级锁，其他线程会通过自旋的形式获取锁。

长时间自旋非常消耗 CPU 资源，一个线程持有锁，其他线程只能空耗 CPU，无法执行有效任务（忙等现象）。但是在轻微锁竞争的情况下，允许段时间的忙等，换取线程在用户态和内核态之间频繁切换的开销。

忙等是有限度的（计数器记录自旋次数），达到一定的次数，轻量级锁会升级为重量级锁（通过 CAS 修改锁标志）当一个线程获取锁后，其余所有等待该锁的线程会处于阻塞状态（控制权交由操作系统，会出现频繁对线程状体的切换、挂起、唤醒从而消耗大量资源）。



### synchronized 和 volatile 的区别：

1. volatile 是线程同步的轻量级实现，所以 volatile 的性能优于 synchronized 。但是volatile 只能用于变量，而 synchronized 可以修饰方法、代码块。
2. volatile 能保证数据可见性，但不能保证数据原子性，synchronized 两者都能保证。
3. volatile 关键字主要解决变量在多个线程之间的可见性。synchronized 主要解决多线程访问资源的同步性。



### synchronized 和 Lock 的区别：

1. synchronized 编码简单，锁机制由 JVM 实现，竞争不激烈的情况下性能更好。Lock 功能更强大更灵活，竞争激烈时性能更好。
2. 锁机制不同，synchronized 是 JVM 层面实现，Lock 是 JDK 代码实现，需要手动释放（在 finally 中释放 unlock() ）
3. synchronized 能够用于代码块、方法。 Lock 只能写在代码里，并且 Lock 支持公平锁，非公平锁，读写锁等。



### CAS （Compare And Swap） 乐观锁

每次不加锁，假设没有冲突去完成某项工作，因冲突失败就重试，直到成功。

CAS 原理：在内存值和期望值相同时，将内存值更新为需要的值。内存值 V，期望值 A，更新值 B   ----> if V == A, UPDATE V = B;

应用：java.util.concurrent.atomic 包中的原子类

例子：内存值 V = 10，线程一相加 1，即 V = 10， A = 10，B = 11

但是线程二提前修改，使得 V = 11，此时线程一，V != A，无法完成更新。

线程一重新读取，V = 11，A = 11，B = 12，此时 V == A，更新 V = 12

**优点**：非阻塞的轻量级乐观锁，在资源竞争不激烈的情况下，性能高，相比 synchronized 省去了加锁、解锁、唤醒等操作。

**缺点**：

1. ABA 问题：现有线程一二。线程二将 A 的值改为 B，后又将 B 的值改为 A，此时线程一认为 A 的值没有被修改过。**解决**：追加版本号，1A --> 2B --> 3A
2. 自旋时间过长，消耗 CPU 资源



### 反射

**反射：程序运行时动态加载类并获取类的信息，从而操纵类或对象的属性和方法。**

#### 为什么需要反射？

1. 某些时候只有 .class，没有 .java
2. 有的类用到的时候再动态加载，能减少 JVM 启动时间。
3. 几乎所有通用框架的开发都离不开反射。



### 序列化和反序列化

**序列化**：把对象转换成有序的字节流，以便在网络上传输或存在本地文件中。

**反序列化**：根据获取到的字节流保存的对象状态和描述信息，重建对象。



### 双亲委派模型

四级类加载器：启动类加载器、扩展类加载器、应用类加载器、自定义类加载器

#### 什么是双亲委派模型？

如果一个类加载器收到了类加载请求，它首先不会自己去尝试加载这个类，而是把这个类的加载请求委派给父类加载器去完成，每一个层次的加载器都是如此，因此所有的类加载请求都会传给顶层的启动类加载器，只有当父加载器反馈自己无法完成类加载请求时，子加载器才会尝试自己去加载。

#### 为什么需要双亲委派模型？

1. 双亲委派模型的方式，可以避免类的重复加载，当父加载器已经加载过某一个类的时候，子加载器就不会重新再加载这个类。
2. 通过双亲委派的方式，还保证了安全性。像启动类加载器只会加载 JAVA_HOME 中的 jar 包里的类，这样可以避免有人自定义一个有破坏功能的类被加载，可以有效防止核心 Java API 被篡改。

#### 破坏双亲委派模型的例子？（记住前俩）

1. 实现热插拔热部署的工具。为了让代码能够动态加载而无需重启，实现方式就是把模块连同类加载器一起换掉实现代码的热替换。
2. JDBC 4.0之后实际上是不需要调用 Class.forName 来加载驱动，只需要把驱动的 jar 包放到工程的类加载路径里， 驱动就会被自动加载（这种自动加载采用的技术叫 SPI）。
3. Tomcat。对于各个webapp中的class和lib，需要相互隔离，不能出现一个应用加载的类库影响另一个应用的情况（不同应用程序可能依赖同一个第三方类库的不同版本，但是不同版本的类库中某一个类的全路径可能是一样的）。Tomcat造了一堆自己的classloader（当然Tomcat也有热部署的原因）。



### HashMap

#### HashMap 扩容：

**HashMap 扩容时机**：当 map 中包含的 Entry 的数量大于等于 threshold = loadFactor * capacity 的时候，且新建的 Entry 刚好落在一个非空的桶上，此时触发扩容机制，将其容量扩大为 2 倍。

**扩容步骤**：

1. 扩容数组容量到原来的两倍（如果扩容前数组容量已经达到了 2 的 20 次方，就会修改阈值到 int 的最大值，之后也不会扩容）。
2. 转移现有数据到新的 Entry 数组里（1.7 的时候，会重新计算每个元素在新数组中的位置，1.8 之后是判断，当前元素是否需要移位，移位后的位置就是当前位置加扩容容量）。



### ConcurrentHashMap 线程安全原理：....

分段机制：segment 分段锁，每段加 ReentrantLock 可重入锁。

定位元素：先找 segment 数组，再在 segment 中 HashEntry 数组下标。



### JDBC 连接池

为了避免频繁地创建和销毁 JDBC 连接，可以通过连接池复用已经创建好的连接。

常见的 JDBC 连接池有：HikariCP，C3P0，BoneCP，Druid



### Java 中的内存泄漏

Java 中的内存泄漏，广义通俗的说，就是：不再会被使用的对象的内存空间无法被回收，就是内存泄漏。

对象都是有生命周期的，有的长，有的短。**如果长生命周期的对象持有短生命周期对象的引用，就很有可能出现内存泄漏。**



#### 消息队列常用的使用场景：

1. 异步处理
2. 应用解耦：订单系统：用户下单，订单系统完成持久化处理，将消息写入消息队列，返回用户订单下单成功。库存系统：订阅下单的消息，采用拉 / 推的方式，获取下单的信息，库存系统根据下单信息，进行库存操作，实现了两者的解耦。
3. 流量削峰：秒杀活动一般会因为流量过大，导致流量的暴增，应用挂掉。该问题可通过加入消息队列实现。用户的请求，服务器接收之后，首先写入消息队列。假如消息队列长度超过最大数量，则直接抛弃用户请求或跳转到错误页面。秒杀业务会根据消息队列中的请求消息，再做后续处理。
4. 日志处理
5. 消息通讯：消息队列一般内置了高效的通信机制，因此也可以用在纯的消息通讯。



### 分布式 CAP

C ：一致性，所有节点同一时间的数据应完全一致（每次写操作之后的读操作，都必须返回该值）。

A ：可用性，只要收到用户的请求，服务器就必须给出回应。（用户可以选择向分区1或是分区2发起读的操作。不管是哪个服务器收到了读的请求，就必须告诉用户，应当读取到的内容）。

P ：分区容错，分布式系统在某节点或网络分区故障的时候，仍能对外提供满足一致性和可用性的服务。



**CAP三性只能同时满足两个**

CA without P ：如果不要求 P（不允许分区，无异于单机），C（强一致性）和 A（可用性）是可以得到保证的。

CP without A ：如果不要求A（可用性），可以保证各分区之间强一致性，但会导致分区之间同步时间的无限延长（例如网络故障时的只读不写）。

AP without C ：放弃一致性，来保证节点的高可用性和分区容错。但是放弃一致性就导致了全局数据的不一致。



### AbstractQueuedSynchronizer （AQS）

AbstractQueuedSynchronizer：抽象的队列式同步器，AQS 定义了一套多线程访问共享资源的同步器框架，许多同步类实现都依赖于它，如常用的 ReentrantLock / Semaphore / CountDownLatch

**原理**：AQS 核心思想是，如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并且将共享资源设置为锁定状态。如果被请求的共享资源被占用，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制，这个机制 AQS 是使用队列锁实现的，即将暂时获取不到锁的线程加入到队列中。

**整体实现框架**：它维护了一个 volatile int state（代表共享资源，使用 volatile 修饰保证其在各个线程之间的可见性）和一个 FIFO 线程等待队列（多线程争用资源被阻塞时会加入此队列）。

有关 state 的访问方式有三种：getState()，setState()，和 compareAndSetState()。

#### AQS定义了两种资源共享的方式：

**Exclusive（独占）**：只有一个线程能执行 ，如 ReentrantLock，又可以分为公平锁和非公平锁。**公平锁**：按照线程在队列中的排队顺序，先到者先拿到锁。**非公平锁**：当线程要获取锁时，无视队列顺序直接去抢锁，抢不到锁再加入队列。

**Share（共享）**：多个线程能够同时执行，如 Semaphore / CoundownLatch。



不同的自定义同步器争用共享资源的方式也不同。**自定义同步器在实现时只需要实现共享资源 state 的获取与释放方式即可。** 自定义同步器实现时主要实现以下几种方法：

isHeldExclusive()：该线程是否正在独占资源，只有用到 condition 才需要实现它。

tryAcquire(int): 独占方式。尝试获取资源，成功返回true，失败返回false。

tryRelease(int): 独占方式。尝试释放资源，成功返回true，失败返回false。

tryAcquireShared(int): 共享方式。尝试获取资源。负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。

tryReleaseShared(int): 共享方式。尝试释放资源，如果释放后允许唤醒后续等待节点则返回true，否则返回false。



以 ReentrantLock 为例，state 初始化为 0，表示未锁定状态。A 线程 lock() 时，会调用 tryAcquire() 独占该锁并将 state += 1。此后，其他进程再 tryAcquire() 时就会失败，直到 A 线程 unlock() 到 state = 0（即释放锁），其他线程才有机会获取该锁。当然，释放锁之前，A 线程自己是可以重复获取此锁的（state 会累加，这就是可重入锁的概念）。但是要注意的是，获取多少次就要释放多少次，这样才能保证 state 是能回到 0 的。



以 CountDownLatch 为例，任务分为 N 个子线程去执行，state 也初始化为 N （注意 N 要与线程个数一致）。这 N个子线程是并行执行的，每个子线程执行完后 countDown() 一次，state 会以 CAS 的方式减1，等到所有子线程都执行完后 state = 0.



### 异常处理的时候，finally 代码块的重要性：

finally 是异常处理的一部分，用于释放资源。一般来说，finally 代码块中的代码一定会执行。

有时候，程序在 try 块中打开了一些物理资源（例如数据库连接、网络连接和磁盘文件等），这些物理资源必须显示回收。（Java 的垃圾回收机制不会回收任何物理资源，垃圾回收机制只能回收堆内存中对象占用的内存）。

为了保证一定能回收 try 块中打开的物理资源，异常处理机制提供了 finaly 块。不管 try 块中的代码是否出现异常，也不管哪个 catch 块被执行，finally 总是执行。
